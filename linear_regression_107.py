# -*- coding: utf-8 -*-
"""linear regression 107

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ivuLw6wXPYNsGuU4W2riAz3auf3Ll2Bc
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data_df= pd.read_csv('/content/Fish.csv')

data_df.head()

print(data_df.info())

data_df.describe()

data_df["Species"].value_counts()

data_df.hist(bins=50,figsize=(20,20))

#pairwise correlation
cor = data_df.corr()
cor["Weight"]

g = sns.pairplot(data_df, kind='scatter', hue='Species')

#species
Species = data_df[["Species"]]
Species.head()

sns.countplot(Species["Species"])

#weight
Weight = data_df [["Weight"]]
Weight.head()

sns.boxplot(Weight["Weight"])

#Length
Length = data_df[["Length1","Length2","Length3"]]

Length.head()

sns.boxplot(data=Length, orient="h", palette="Set2")

#Height
Height = data_df[["Height"]]
Height.head()

sns.boxplot(Height["Height"])

#width
Width = data_df[["Width"]]
Width.head()

sns.boxplot(Width["Width"])

from sklearn.model_selection import train_test_split
train_set,test_set = train_test_split(data_df,random_state=40, test_size=0.3)

y_train = train_set["Weight"]
data = train_set.drop(['Weight'], axis=1)
y_test = test_set["Weight"]
data_test = test_set.drop(['Weight'], axis=1)

y_test = test_set["Weight"]
test = test_set.drop(['Weight'], axis=1)

from sklearn.preprocessing import Normalizer
from sklearn.preprocessing import LabelEncoder
norm = Normalizer()
encoder = LabelEncoder()
data["Species"] = encoder.fit_transform(data["Species"])
data_test["Species"] = encoder.fit_transform(data_test["Species"])

#model
from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(data, y_train)
lin_reg.score(data,y_train)

from sklearn.metrics import mean_squared_error, r2_score
y_pred = lin_reg.predict(data_test)
t = np.linspace(0,len(y_pred),len(y_pred))
plt.plot(t,y_pred,'r')
plt.plot(t,y_test,'g')
plt.axis(False)
plt.legend(["Predicted values", "Test values"], loc ="lower right")
plt.show()
print("The model  explains "+str(int(r2_score(y_pred, y_test)*100))+"% of  test data ")

#Random Forest Regressor
from sklearn.ensemble import RandomForestRegressor
forest_reg = RandomForestRegressor()
forest_reg.fit(data, y_train)
forest_reg.score(data,y_train)

from sklearn.metrics import mean_squared_error, r2_score
y_pred = forest_reg.predict(data_test)
t = np.linspace(0,len(y_pred),len(y_pred))
plt.plot(t,y_pred,'r')
plt.plot(t,y_test,'g')
plt.axis(False)
plt.legend(["Predicted values", "Test values"], loc ="lower right")
plt.show()
print("The model could explain "+str(int(r2_score(y_pred, y_test)*100))+"% of the test data ")

#Grid Search CV
from sklearn.model_selection import GridSearchCV
param_grid = [
{'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},
{'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},
]
forest_reg = RandomForestRegressor()
grid= GridSearchCV(estimator=forest_reg, param_grid=param_grid, cv = 3, n_jobs=-1)
grid_result = grid.fit(data, y_train)
print("The best score is: %f using %s" % (grid_result.best_score_, grid_result.best_params_))

from sklearn.metrics import mean_squared_error, r2_score
y_pred = grid.predict(data_test)
t = np.linspace(0,len(y_pred),len(y_pred))
plt.plot(t,y_pred,'r')
plt.plot(t,y_test,'g')
plt.axis(False)
plt.legend(["Predicted values", "Test values"], loc ="lower right")
plt.show()
print("The model could explain "+str(int(r2_score(y_pred, y_test)*100))+"% of the test data ")